# need to set either broker.list or zk.connect

# configure brokers statically
# format: brokerid1:host1:port1,brokerid2:host2:port2 ...
# broker.list=

# zk connection string
# comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"
zk.connect=<% @zookeeper_search.each do |z|-%><%=z['fqdn']-%>:<%=z['zookeeper']['client_port']-%><%end-%>

# timeout in ms for connecting to util
zk.connectiontimeout.ms=1000000

# util session timeout; default is 6000
#zk.sessiontimeout.ms=

# name of the partitioner class for partitioning events; default partition
# spreads data randomly
#partitioner.class=

# specifies whether the messages are sent asynchronously (async) or
# synchronously (sync)
producer.type=async

# specify the compression codec for all data generated: 0: no compression, 1:
# gzip
compression.codec=1

# message encoder
serializer.class=kafka.serializer.StringEncoder

# allow topic level compression
#compressed.topics=

# max message size; messages larger than that size are discarded; default is
# 1000000
#max.message.size=


############################# Async Producer #############################
# maximum time, in milliseconds, for buffering data on the producer queue 
#queue.time=

# the maximum size of the blocking queue for buffering on the producer 
#queue.size=

# Timeout for event enqueue:
# 0: events will be enqueued immediately or dropped if the queue is full
# -ve: enqueue will block indefinitely if the queue is full
# +ve: enqueue will block up to this many milliseconds if the queue is full
queue.enqueueTimeout.ms=-1

# the number of messages batched at the producer 
#batch.size=

# the callback handler for one or multiple events 
#callback.handler=

# properties required to initialize the callback handler 
#callback.handler.props=

# the handler for events 
#event.handler=

# properties required to initialize the event handler 
#event.handler.props=

